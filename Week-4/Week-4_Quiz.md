**1.** What are the current limitations of AI technology? (Select all that apply)
- [x] AI technology can discriminate
- [x] Explainability is hard
- [x] AI technology can be biased
- [x] AI technology is susceptible to adversarial attacks
- [ ] There are no limitations to AI technology

**2.** What is the Goldilocks Rule of AI?
- [ ] An AI winter is coming
- [ ] AI’s technology will continue to grow and can only benefit society
- [ ] One should allocate many resources to defend the world from giant killer robots
- [x] One shouldn’t be too optimistic or too pessimistic about AI technology

**3.** Say you are building an AI system to help make diagnoses from X-ray scans. Which of the following statements about explainability of AI do you agree with?
- [ ] AI systems are intrinsically “black box” and cannot give any explanation for their outputs.
- [ ] Explainability is usually achieved through building a chatbot to talk to the user to explain its outputs.
- [x] Lack of explainability can hamper users’ willingness to trust and adopt an AI system.
- [ ] Most AI systems are highly explainable, meaning that it’s easy for a doctor to figure out why an AI system gave a particular diagnosis.

**4.** Using current AI technology, if a machine learning system learns from text that reflects unhealthy biases/stereotypes, then the resulting AI software may also exhibit similarly unhealthy biases/stereotypes.
- [x] True
- [ ] False

**5.** Using current AI technology, if a machine learning system learns only from text that is completely neutral and does not reflect any gender biases, then we would expect it to exhibit no, or at most minimal, gender bias.
- [x] True
- [ ] False

**6.** Which of these are good practices for addressing bias in AI? (Select all that apply)
- [x] Systematic auditing processes to check for bias
- [x] Technical solution such as “zeroing out” bias
- [ ] Using an adversarial attack on the AI system to change its outputs to be less biased
- [x] Using more inclusive/less biased data

**7.** Which of these are examples of adversarial attacks on an AI system? (Select all that apply)
- [ ] Using AI to synthesize a fake video of a politician saying something they never actually said.
- [x] Subtly changing an image to make an AI system mistakenly recognize a dog as a cat.
- [x] Adding a sticker to a stop sign to make an AI system fail to detect it. 
- [x] Subtly modifying an audio clip to make a speech recognition system think someone said “Yes, authorized” when they actually said “No, reject.”

**8.** If a developing economy has a strong and thriving coffee bean manufacturing industry (or some other vertical industry), then it has an advantage in applying AI to coffee bean manufacturing (or other vertical industry).
- [x] True
- [ ] False

**9.** What are the jobs that AI is most likely to displace over the next several years?
- [x] Jobs that comprise primarily of routine, repetitive work
- [ ] Most jobs involving office work (white collar jobs)
- [ ] Jobs that comprise primarily of non-routine, non-repetitive work
- [ ] All jobs will be displaced

**10.** Congratulations! You deserve a pat on the back for finishing this course.
- [x] True
- [ ] False
